{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af57cfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import math, os, torch\n",
    "\n",
    "# ==========================\n",
    "# ðŸ”§ CONFIGURATION\n",
    "# ==========================\n",
    "\n",
    "input_file = \"/content/GPC OG only Bricks no Duplicates.xlsx\"\n",
    "output_file = f\"GPC only Bricks Arabic Translated.xlsx\"\n",
    "\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-ar\"\n",
    "batch_size = 32\n",
    "save_every = 500  # Save progress every 500 rows\n",
    "\n",
    "# ==========================\n",
    "# ðŸš€ MODEL INITIALIZATION\n",
    "# ==========================\n",
    "print(\"ðŸ”„ Loading model and tokenizer...\")\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "print(f\"âœ… Model loaded on device: {device}\")\n",
    "\n",
    "# ==========================\n",
    "# ðŸ“‚ DATA LOADING\n",
    "# ==========================\n",
    "print(f\"ðŸ“– Reading data from {input_file}...\")\n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "# REMOVE slicing â†’ translate full dataset\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Resume progress if exists\n",
    "if os.path.exists(output_file):\n",
    "    translated_df = pd.read_excel(output_file)\n",
    "    print(f\"ðŸ” Resuming from existing progress: {output_file}\")\n",
    "else:\n",
    "    translated_df = pd.DataFrame()\n",
    "\n",
    "# ==========================\n",
    "# ðŸ§  TRANSLATION FUNCTION\n",
    "# ==========================\n",
    "def translate_batch(texts):\n",
    "    # Skip empty or NaN entries\n",
    "    texts = [t if isinstance(t, str) and t.strip() else \"\" for t in texts]\n",
    "    prefixed_texts = [\">>ara<< \" + t for t in texts]\n",
    "\n",
    "    inputs = tokenizer(prefixed_texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    translated = model.generate(**inputs, max_length=512)\n",
    "    return [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
    "\n",
    "# ==========================\n",
    "# âš™ TRANSLATION LOOP\n",
    "# ==========================\n",
    "print(\"ðŸŒ Starting translation process...\\n\")\n",
    "\n",
    "for col in df.columns:\n",
    "    print(f\"ðŸˆ¶ Translating column: {col}\")\n",
    "    texts = df[col].astype(str).tolist()\n",
    "    translated_texts = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=f\"Translating {col}\"):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        translated_batch = translate_batch(batch)\n",
    "        translated_texts.extend(translated_batch)\n",
    "\n",
    "        # Save progress every save_every rows\n",
    "        if i % (save_every * batch_size) == 0 and i > 0:\n",
    "            partial_df = pd.concat([df, translated_df], axis=1)\n",
    "            partial_df.to_excel(output_file, index=False)\n",
    "\n",
    "    # Add translated column to translated_df\n",
    "    translated_df[col + \"_ar\"] = translated_texts\n",
    "\n",
    "# ==========================\n",
    "# ðŸ’¾ FINAL SAVE\n",
    "# ==========================\n",
    "final_df = pd.concat([df, translated_df], axis=1)\n",
    "final_df.to_excel(output_file, index=False)\n",
    "\n",
    "print(f\"\\nâœ… Translation complete for !\")\n",
    "print(f\"ðŸ’¾ Saved to: {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
